[WARNING] - META - domain_type: DEFAULT
[WARNING] - META - model_run: XLM_RoBerta_ENGLISH-XLM_RoBerta
[WARNING] - META - model_type: default
[WARNING] - META - tokenizer_type: default
[WARNING] - META - training: False
[WARNING] - META - max_seq_length: 256
[WARNING] - META - random_seed: 42
[WARNING] - META - training_batch_size: 16
[WARNING] - META - validation_batch_size: 16
[WARNING] - META - learning_rate: 3e-05
[WARNING] - META - epsilon: 1e-08
[WARNING] - META - weight_decay: 0.1
[WARNING] - META - epochs: 5
[WARNING] - META - scheduler: LinearWarmup
[WARNING] - META - optimizer: AdamW
[WARNING] - META - max_grad_norm: 1.0
[WARNING] - META - full_finetuning: True
[WARNING] - META - debugging: False
[WARNING] - META - log_file: ./Switch_Files/XLM_RoBerta_ENGLISH-XLM_RoBerta-Inference
[WARNING] - META - datetime: 11-03-2023_21:02:42
[WARNING] - META - mode: SWITCHES

[WARNING] - META - Testing Datatset: 155
[CRITICAL] - PORGRESS - 11-03-2023 21:02:42 - Starting Inference
[INFO] - RESULTS - inference.py.<117> - Validation Hamming Score: 0.33225806451612905  |  Validation Exact Match Ratio: 0.0967741935483871 |  Validation Accuracy Score: 0.9090322580645162
[INFO] - RESULTS - inference.py.<118> - Classification Report:
[INFO] - RESULTS - inference.py.<119> - 
                                                     precision    recall  f1-score   support

                                    Loaded Language       0.68      0.65      0.66        68
      Obfuscation, Intentional vagueness, Confusion       0.00      0.00      0.00         2
                           Appeal to fear/prejudice       0.67      0.13      0.22        15
                                Appeal to authority       0.00      0.00      0.00         2
                                       Whataboutism       0.40      0.33      0.36         6
                                            Slogans       0.00      0.00      0.00         7
                          Exaggeration/Minimisation       0.46      0.37      0.41        51
               Black-and-white Fallacy/Dictatorship       0.00      0.00      0.00         5
                                             Smears       0.66      0.65      0.65        57
                                              Doubt       1.00      0.17      0.29         6
                                          Bandwagon       0.00      0.00      0.00         1
                              Name calling/Labeling       0.58      0.49      0.53        61
                               Reductio ad hitlerum       0.00      0.00      0.00         3
           Presenting Irrelevant Data (Red Herring)       1.00      0.11      0.20         9
                                         Repetition       0.00      0.00      0.00         2
Misrepresentation of Someone's Position (Straw Man)       0.00      0.00      0.00         3
                         Thought-terminating clich√©       0.00      0.00      0.00         6
                   Glittering generalities (Virtue)       0.25      0.17      0.20         6
                                        Flag-waving       0.33      0.17      0.22         6
                          Causal Oversimplification       1.00      0.15      0.27        13

                                          micro avg       0.60      0.43      0.50       329
                                          macro avg       0.35      0.17      0.20       329
                                       weighted avg       0.57      0.43      0.46       329
                                        samples avg       0.48      0.36      0.39       329

[CRITICAL] - PORGRESS - 11-03-2023 21:02:55 - Inference Complete
