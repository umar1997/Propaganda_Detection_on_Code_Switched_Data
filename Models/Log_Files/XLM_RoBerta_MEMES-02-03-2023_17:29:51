[WARNING] - META - domain_type: MEMES
[WARNING] - META - model_run: XLM_RoBerta_MEMES
[WARNING] - META - model_type: xlm-roberta-base
[WARNING] - META - tokenizer_type: xlm-roberta-base
[WARNING] - META - training: True
[WARNING] - META - max_seq_length: 256
[WARNING] - META - random_seed: 42
[WARNING] - META - training_batch_size: 16
[WARNING] - META - validation_batch_size: 16
[WARNING] - META - learning_rate: 3e-05
[WARNING] - META - epsilon: 1e-08
[WARNING] - META - weight_decay: 0.1
[WARNING] - META - epochs: 10
[WARNING] - META - scheduler: LinearWarmup
[WARNING] - META - optimizer: AdamW
[WARNING] - META - max_grad_norm: 1.0
[WARNING] - META - full_finetuning: True
[WARNING] - META - debugging: False
[WARNING] - META - log_file: ./Log_Files/XLM_RoBerta_MEMES-02-03-2023_17:29:51
[WARNING] - META - datetime: 02-03-2023_17:29:51

[WARNING] - META - Training Datatset: 688
[WARNING] - META - Validation Datatset: 89
[WARNING] - META - Testing Datatset: 155
[WARNING] - META - Vocab Size: 250002

[CRITICAL] - PORGRESS - 02-03-2023 17:30:01 - Model + Tokenizer Initialized
[CRITICAL] - PORGRESS - 02-03-2023 17:30:02 - Tokenizing sentences and encoding labels
[CRITICAL] - PORGRESS - 02-03-2023 17:30:02 - Data Loaders Created
[CRITICAL] - PORGRESS - 02-03-2023 17:30:02 - Training Started
[INFO] - RESULTS - training.py.<115> - Epoch #1
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 1: 0.43072577583235366
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 1: 0.4586678644021352
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8089887640449438  |  Validation Exact Match Ratio: 0.0
[INFO] - RESULTS - training.py.<206> - Duration: 13.498635053634644

[INFO] - RESULTS - training.py.<115> - Epoch #2
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 2: 0.246862017831137
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 2: 0.372846116622289
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8370786516853933  |  Validation Exact Match Ratio: 0.033707865168539325
[INFO] - RESULTS - training.py.<206> - Duration: 13.130182981491089

[INFO] - RESULTS - training.py.<115> - Epoch #3
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 3: 0.22881134200927822
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 3: 0.3753875096638997
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8550561797752809  |  Validation Exact Match Ratio: 0.056179775280898875
[INFO] - RESULTS - training.py.<206> - Duration: 13.44014286994934

[INFO] - RESULTS - training.py.<115> - Epoch #4
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 4: 0.21490881574708362
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 4: 0.3294609785079956
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8769662921348315  |  Validation Exact Match Ratio: 0.0
[INFO] - RESULTS - training.py.<206> - Duration: 13.364041090011597

[INFO] - RESULTS - training.py.<115> - Epoch #5
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 5: 0.19679248523573542
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 5: 0.3254273434480031
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8764044943820225  |  Validation Exact Match Ratio: 0.056179775280898875
[INFO] - RESULTS - training.py.<206> - Duration: 13.2012779712677

[INFO] - RESULTS - training.py.<115> - Epoch #6
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 6: 0.18601406313652216
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 6: 0.31165560086568195
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8837078651685393  |  Validation Exact Match Ratio: 0.0449438202247191
[INFO] - RESULTS - training.py.<206> - Duration: 13.184576272964478

[INFO] - RESULTS - training.py.<115> - Epoch #7
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 7: 0.1656879935153695
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 7: 0.3447119990984599
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8775280898876404  |  Validation Exact Match Ratio: 0.033707865168539325
[INFO] - RESULTS - training.py.<206> - Duration: 13.199336290359497

[INFO] - RESULTS - training.py.<115> - Epoch #8
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 8: 0.14862453764261202
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 8: 0.3550407538811366
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8803370786516854  |  Validation Exact Match Ratio: 0.0449438202247191
[INFO] - RESULTS - training.py.<206> - Duration: 13.217557191848755

[INFO] - RESULTS - training.py.<115> - Epoch #9
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 9: 0.13045752949492875
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 9: 0.3945869157711665
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8820224719101124  |  Validation Exact Match Ratio: 0.02247191011235955
[INFO] - RESULTS - training.py.<206> - Duration: 13.259709358215332

[INFO] - RESULTS - training.py.<115> - Epoch #10
[INFO] - RESULTS - training.py.<148> - Average Train Loss For Epoch 10: 0.11764017319263415
[INFO] - RESULTS - training.py.<184> - Average Val Loss For Epoch 10: 0.38361625373363495
[INFO] - RESULTS - training.py.<194> - Validation Hamming Score: 0.8853932584269663  |  Validation Exact Match Ratio: 0.033707865168539325
[INFO] - RESULTS - training.py.<206> - Duration: 13.235713481903076

[INFO] - RESULTS - training.py.<215> - Validation Hamming Score: 0.8853932584269663  |  Validation Exact Match Ratio: 0.033707865168539325
[INFO] - RESULTS - training.py.<216> - Classification Report:
[INFO] - RESULTS - training.py.<217> - 
                                                     precision    recall  f1-score   support

                                    Loaded Language       0.48      0.80      0.60        40
      Obfuscation, Intentional vagueness, Confusion       0.00      0.00      0.00         1
                           Appeal to fear/prejudice       0.00      0.00      0.00         9
                                Appeal to authority       0.00      0.00      0.00         1
                                       Whataboutism       0.00      0.00      0.00         3
                                            Slogans       0.00      0.00      0.00         3
                          Exaggeration/Minimisation       0.00      0.00      0.00        30
               Black-and-white Fallacy/Dictatorship       0.00      0.00      0.00         3
                                             Smears       0.50      0.25      0.33        40
                                              Doubt       0.00      0.00      0.00         3
                                          Bandwagon       0.00      0.00      0.00         1
                              Name calling/Labeling       0.49      0.51      0.50        37
                               Reductio ad hitlerum       0.00      0.00      0.00         0
           Presenting Irrelevant Data (Red Herring)       0.00      0.00      0.00         5
                                         Repetition       0.00      0.00      0.00         1
Misrepresentation of Someone's Position (Straw Man)       0.00      0.00      0.00         2
                         Thought-terminating clich√©       0.00      0.00      0.00         4
                   Glittering generalities (Virtue)       0.00      0.00      0.00         4
                                        Flag-waving       0.00      0.00      0.00         3
                          Causal Oversimplification       0.00      0.00      0.00         8

                                          micro avg       0.48      0.31      0.37       198
                                          macro avg       0.07      0.08      0.07       198
                                       weighted avg       0.29      0.31      0.28       198
                                        samples avg       0.40      0.28      0.31       198

[CRITICAL] - PORGRESS - 02-03-2023 17:32:17 - Training Finished
[CRITICAL] - PORGRESS - 02-03-2023 17:32:17 - Model Saved
